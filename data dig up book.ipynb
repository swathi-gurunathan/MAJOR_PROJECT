{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "051f3de7-2b79-446f-9b5f-6444e1c54b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: extract-msg in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (0.54.1)\n",
      "Requirement already satisfied: olefile==0.47 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from extract-msg) (0.47)\n",
      "Requirement already satisfied: tzlocal<6,>=4.2 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from extract-msg) (5.3.1)\n",
      "Requirement already satisfied: compressed-rtf<2,>=1.0.6 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from extract-msg) (1.0.7)\n",
      "Requirement already satisfied: ebcdic<2,>=1.1.1 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from extract-msg) (1.1.1)\n",
      "Requirement already satisfied: beautifulsoup4<4.14,>=4.11.1 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from extract-msg) (4.13.4)\n",
      "Requirement already satisfied: RTFDE<0.2,>=0.1.1 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from extract-msg) (0.1.2)\n",
      "Requirement already satisfied: red-black-tree-mod<=1.23,>=1.20 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from extract-msg) (1.22)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from beautifulsoup4<4.14,>=4.11.1->extract-msg) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from beautifulsoup4<4.14,>=4.11.1->extract-msg) (4.13.2)\n",
      "Requirement already satisfied: lark~=1.1.8 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from RTFDE<0.2,>=0.1.1->extract-msg) (1.1.9)\n",
      "Requirement already satisfied: oletools>=0.56 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from RTFDE<0.2,>=0.1.1->extract-msg) (0.60.2)\n",
      "Requirement already satisfied: tzdata in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from tzlocal<6,>=4.2->extract-msg) (2025.2)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from oletools>=0.56->RTFDE<0.2,>=0.1.1->extract-msg) (3.2.3)\n",
      "Requirement already satisfied: easygui in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from oletools>=0.56->RTFDE<0.2,>=0.1.1->extract-msg) (0.98.3)\n",
      "Requirement already satisfied: colorclass in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from oletools>=0.56->RTFDE<0.2,>=0.1.1->extract-msg) (2.2.2)\n",
      "Requirement already satisfied: pcodedmp>=1.2.5 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from oletools>=0.56->RTFDE<0.2,>=0.1.1->extract-msg) (1.2.6)\n",
      "Requirement already satisfied: msoffcrypto-tool in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from oletools>=0.56->RTFDE<0.2,>=0.1.1->extract-msg) (5.4.2)\n",
      "Requirement already satisfied: win-unicode-console in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from pcodedmp>=1.2.5->oletools>=0.56->RTFDE<0.2,>=0.1.1->extract-msg) (0.5)\n",
      "Requirement already satisfied: cryptography>=39.0 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from msoffcrypto-tool->oletools>=0.56->RTFDE<0.2,>=0.1.1->extract-msg) (44.0.2)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from cryptography>=39.0->msoffcrypto-tool->oletools>=0.56->RTFDE<0.2,>=0.1.1->extract-msg) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from cffi>=1.12->cryptography>=39.0->msoffcrypto-tool->oletools>=0.56->RTFDE<0.2,>=0.1.1->extract-msg) (2.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install extract-msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2fc90d4-deae-4a28-9cc8-8534890756a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import extract_msg\n",
    "\n",
    "input_folder = r\"C:\\Users\\shril\\Downloads\\Mail loads\"\n",
    "output_folder = r\"/MAJOR PROJECT/mail op msg\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".msg\"):\n",
    "        msg = extract_msg.Message(os.path.join(input_folder, filename))\n",
    "        with open(os.path.join(output_folder, filename.replace('.msg', '.eml')), 'w', encoding='utf-8') as f:\n",
    "            f.write(msg.as_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5449b790-06d3-44ef-a091-3d7f19830455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shril\\MAJOR PROJECT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93b444d1-3e9a-4601-9f56-dca0b54413c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: Dean - Academics and IQAC <iqac@cmrit.ac.in>\n",
      "Subject: Fwd: Applications Open: DMP 2025 Open-Source Mentorship Program | PPO\n",
      " for Top Performers\n",
      "Body: ---------- Forwarded message ---------\n",
      "From: Poonam Tijare <director.placement@cmrit.ac.in>\n",
      "Date: Wed, Apr 23, 2025 at 8:08 PM\n",
      "Subject: Fwd: Applications Open: DMP 2025 Open-Source Mentorship Progr...\n",
      "--------------------------------------------------\n",
      "From: Instructables <no-reply@mail.newsletter.instructables.com>\n",
      "Subject: Autonomous Home Robot\n",
      "Body: <html xmlns=\"http://www.w3.org/1999/xhtml\"><head><meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/><meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/><meta conten...\n",
      "--------------------------------------------------\n",
      "From: Vice Principal CMRIT <viceprincipal@cmrit.ac.in>\n",
      "Subject: Fwd: Cultura’25 is Here! Join the Ultimate Techno-Cultural Fest on April 25 & 26!\n",
      "Body: Dr B Narasimha Murthy\n",
      "Vice Principal, CMRIT\n",
      "Bangalore\n",
      "\n",
      "---------- Forwarded message ---------\n",
      "From: Kashif Ahmed <kashif.a@cmrit.ac.in>\n",
      "Date: Thu, Apr 24, 2025, 8:29 PM\n",
      "Subject: Fwd: Cultura’25...\n",
      "--------------------------------------------------\n",
      "From: Dean - Academics and IQAC <iqac@cmrit.ac.in>\n",
      "Subject: Fwd: Field Visit and Participation in Awareness Conclave on Assistive\n",
      " Technology 2025\n",
      "Body: Congratulations Srijan S K and other team members!\n",
      "\n",
      "---------- Forwarded message ---------\n",
      "From: Dr.Pappa .M <hod.ece@cmrit.ac.in>\n",
      "Date: Wed, 16 Apr 2025, 7:43 pm\n",
      "Subject: Fwd: Field Visit and Pa...\n",
      "--------------------------------------------------\n",
      "From: Dean - Academics and IQAC <iqac@cmrit.ac.in>\n",
      "Subject: Fwd: BGSCET Bengaluru SAMVIT Fest\n",
      "Body: \n",
      "---------- Forwarded message ---------\n",
      "From: Dr.K. Meenakshi <hod.maths@cmrit.ac.in<mailto:hod.maths@cmrit.ac.in>>\n",
      "Date: Thu, 1 May 2025, 12:53 pm\n",
      "Subject: BGSCET Bengaluru SAMVIT Fest\n",
      "To: Dean ...\n",
      "--------------------------------------------------\n",
      "From: Dean - Academics and IQAC <iqac@cmrit.ac.in>\n",
      "Subject: Fwd: Call for papers | BAIN-2025, International Conference on\n",
      " Business Analytics and intelligence (Hybrid mode)\n",
      "Body: \n",
      "\n",
      "---------- Forwarded message ---------\n",
      "From: Dr. M. Sandeep Kumar <hod.mba@cmrit.ac.in<mailto:hod.mba@cmrit.ac.in>>\n",
      "Date: Mon, Apr 28, 2025 at 4:18 PM\n",
      "Subject: Fwd: Call for papers | BAIN-2025,...\n",
      "--------------------------------------------------\n",
      "From: Vice Principal CMRIT <viceprincipal@cmrit.ac.in>\n",
      "Subject: Fwd: circular\n",
      "Body: \n",
      "\n",
      "Dr B Narasimha Murthy\n",
      "Vice Principal, CMRIT\n",
      "Bangalore\n",
      "\n",
      "---------- Forwarded message ---------\n",
      "From: Dr. Sanjay Jain <principal@cmrit.ac.in<mailto:principal@cmrit.ac.in>>\n",
      "Date: Mon, Apr 28, 2...\n",
      "--------------------------------------------------\n",
      "From: Dean - Academics and IQAC <iqac@cmrit.ac.in>\n",
      "Subject: Fwd: Google Women Techmakers event\n",
      "Body: ---------- Forwarded message ---------\n",
      "From: Dr. Jagadishwari V <hod.ise@cmrit.ac.in<mailto:hod.ise@cmrit.ac.in>>\n",
      "Date: Fri, May 2, 2025 at 1:43 PM\n",
      "Subject: Google Women Techmakers event\n",
      "To: Dean ...\n",
      "--------------------------------------------------\n",
      "From: Dean - Academics and IQAC <iqac@cmrit.ac.in>\n",
      "Subject: Fwd: VTU-CPC- Hackathon - Pace Wisdom\n",
      "Body: \n",
      "---------- Forwarded message ---------\n",
      "From: Poonam Tijare <director.placement@cmrit.ac.in<mailto:director.placement@cmrit.ac.in>>\n",
      "Date: Fri, 2 May 2025, 4:17 pm\n",
      "Subject: Fwd: VTU-CPC- Hackathon ...\n",
      "--------------------------------------------------\n",
      "From: Kavitha Campus House <hostel@cmrit.ac.in>\n",
      "Subject: Introduction of SPACE BASIC APP\n",
      "Body: Dear Students,\n",
      "\n",
      "To enhance the overall hostel experience and streamline administrative\n",
      "processes, we are pleased to introduce *Space Basic* – a comprehensive Hostel\n",
      "Management Application designed...\n",
      "--------------------------------------------------\n",
      "From: Udemy <hello@students.udemy.com>\n",
      "Subject: It’s the last day of our sale. Shop now and save.\n",
      "Body: \n",
      "Courses are on sale today. See the ones other learners are ranking the best.\n",
      "͏ ‌     ﻿ ͏ ‌     ﻿ ͏ ‌     ﻿ ͏ ‌     ﻿ ͏ ‌     ﻿ ͏ ‌     ﻿ ͏ ‌     ﻿ ͏ ‌     ﻿ ͏ ‌     ﻿ ͏ ‌     ﻿ ͏ ‌     ﻿ ͏ ‌     ﻿ ...\n",
      "--------------------------------------------------\n",
      "From: rakuten-product-conference@mail.rakuten.com\n",
      "Subject: Keep the Vibe Alive! Join to Attend Final Sessions of RPC 2025! 🚀\n",
      "Body: <html><head>\n",
      "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\"><style>\n",
      "        body { font-family: Rakuten Sans, sans-serif; font-size:11pt;}\n",
      "        .header { color: #0082cc; }\n",
      "    ...\n",
      "--------------------------------------------------\n",
      "From: Coursera <Coursera@m.learn.coursera.org>\n",
      "Subject: Learn AI product management from Microsoft 🚀\n",
      "Body: \n",
      "Finish this beginner-level program in just three months.\n",
      "͏ ‌     ﻿ ͏ ‌     ﻿ ͏ ‌     ﻿ ͏ ‌     ﻿ ͏ ‌     ﻿ ͏ ‌     ﻿ ͏ ‌     ﻿ ͏ ‌     ﻿ ͏ ‌     ﻿ ͏ ‌     ﻿ ͏ ‌     ﻿ ͏ ‌     ﻿ ͏ ‌     ﻿ ͏ ‌     ﻿ ...\n",
      "--------------------------------------------------\n",
      "From: LeetCode <no-reply@leetcode.com>\n",
      "Subject: LeetCode Weekly Digest\n",
      "Body: [LeetCode]\n",
      "Hi LeetCoder!\n",
      "Choosing between big tech stability and a fast-paced startup isn’t easy. This LeetCoder is weighing Microsoft L61 vs 6sense SDE, and their post highlights what really matter...\n",
      "--------------------------------------------------\n",
      "From: Dean - Academics and IQAC <iqac@cmrit.ac.in>\n",
      "Subject: Fwd: PARKING VENUE FOR CULTURA'25 FEST\n",
      "Body: ---------- Forwarded message ---------\n",
      "From: Kashif Ahmed <kashif.a@cmrit.ac.in>\n",
      "Date: Thu, Apr 24, 2025 at 3:02 PM\n",
      "Subject: PARKING VENUE FOR CULTURA'25 FEST\n",
      "To: Dean - Academics and IQAC <iqac@c...\n",
      "--------------------------------------------------\n",
      "From: Dean - Academics and IQAC <iqac@cmrit.ac.in>\n",
      "Subject: Fwd: Pusa Krishi Startup Grant-in-Aid Incubation Program 2025-For\n",
      " Startups and Students\n",
      "Body: ---------- Forwarded message ---------\n",
      "From: CMRIT . <info@cmrit.ac.in>\n",
      "Date: Wed, Apr 16, 2025 at 2:11 PM\n",
      "Subject: Fwd: Pusa Krishi Startup Grant-in-Aid Incubation Program 2025-For\n",
      "Startups and S...\n",
      "--------------------------------------------------\n",
      "From: \"HackerEarth\" <community_marketing@hackerearth.com>\n",
      "Subject: SmartQ is hiring!\n",
      "Body: HackerEarth\n",
      "[https://img.mmdocdn.com/mailmodo/image/upload/ar_403:77,c_crop/v1637750530/editor/p/76e3b4d2-d919-439a-a73d-33052ecba42b/bfd858131613260f8173e5091c578c00_uhzoic.png]https://t.mmtrkr.com/c...\n",
      "--------------------------------------------------\n",
      "From: Dean - Academics and IQAC <iqac@cmrit.ac.in>\n",
      "Subject: Fwd: Subject: Call for Abstracts – Poster Presentation Awards at 3D GEM 2025 (5th Edition) | IISc Bengaluru\n",
      "Body: ---------- Forwarded message ---------\n",
      "From: msreddy@3dgraphy.in <msreddy@3dgraphy.in>\n",
      "Date: Thu, Apr 24, 2025 at 1:06 PM\n",
      "Subject: Subject: Call for Abstracts – Poster Presentation Awards at 3D GEM...\n",
      "--------------------------------------------------\n",
      "From: Dean - Academics and IQAC <iqac@cmrit.ac.in>\n",
      "Subject: Fwd: 🏆 CSE Students Win GCEM Hacks 2K25 Hackathon – Congratulations!\n",
      "Body: Hearty Congratulations Tarun Prakash Jha, Ronish Rohan, Kavin and Prof.\n",
      "Navaneetha!!\n",
      "\n",
      "---------- Forwarded message ---------\n",
      "From: Dr.Kesavamoorthy-HoD-CSE <hod.cse@cmrit.ac.in>\n",
      "Date: Tue, Apr 29...\n",
      "--------------------------------------------------\n",
      "From: Agnirva.com <Student@agnirva.com>\n",
      "Subject: 📲Future Software Dev? This Internship Is Your Launchpad\n",
      "Body: \n",
      "Code, Build, Win – Your Internship Journey Starts Here‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ‌ ...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import email\n",
    "import os\n",
    "\n",
    "# Specify the directory where your .eml files are saved\n",
    "email_directory = \"C:\\\\Users\\\\shril\\\\Downloads\\\\Mail loads\"  # Change to your folder\n",
    "\n",
    "# Function to process .eml files\n",
    "def process_eml(file_path):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        msg = email.message_from_bytes(f.read())\n",
    "        \n",
    "        # Extract subject and sender\n",
    "        subject, encoding = email.header.decode_header(msg[\"Subject\"])[0]\n",
    "        if isinstance(subject, bytes):\n",
    "            subject = subject.decode(encoding or \"utf-8\")\n",
    "        \n",
    "        from_ = msg.get(\"From\")\n",
    "        \n",
    "        # Extract body (plain text or HTML)\n",
    "        body = \"\"\n",
    "        if msg.is_multipart():\n",
    "            for part in msg.walk():\n",
    "                content_type = part.get_content_type()\n",
    "                content_disposition = str(part.get(\"Content-Disposition\"))\n",
    "                \n",
    "                if \"attachment\" not in content_disposition:\n",
    "                    if content_type == \"text/plain\":\n",
    "                        body = part.get_payload(decode=True).decode()  # Decode text\n",
    "                        break\n",
    "                    elif content_type == \"text/html\":\n",
    "                        body = part.get_payload(decode=True).decode()  # Decode HTML\n",
    "                        break\n",
    "        else:\n",
    "            body = msg.get_payload(decode=True).decode()  # For non-multipart emails\n",
    "\n",
    "        # Print extracted information\n",
    "        print(f\"From: {from_}\")\n",
    "        print(f\"Subject: {subject}\")\n",
    "        print(f\"Body: {body[:200]}...\")  # Print first 200 chars of body\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Process all .eml files in the directory\n",
    "for file_name in os.listdir(email_directory):\n",
    "    if file_name.endswith(\".eml\"):\n",
    "        process_eml(os.path.join(email_directory, file_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55a7063b-5b11-4b7b-a1ed-e24c0a458bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to emails.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty list to store email data\n",
    "email_data = []\n",
    "\n",
    "# Modify the process function to store data\n",
    "def process_eml(file_path):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        msg = email.message_from_bytes(f.read())\n",
    "        \n",
    "        # Extract information\n",
    "        subject, encoding = email.header.decode_header(msg[\"Subject\"])[0]\n",
    "        if isinstance(subject, bytes):\n",
    "            subject = subject.decode(encoding or \"utf-8\")\n",
    "        \n",
    "        from_ = msg.get(\"From\")\n",
    "        body = \"\"\n",
    "        if msg.is_multipart():\n",
    "            for part in msg.walk():\n",
    "                content_type = part.get_content_type()\n",
    "                content_disposition = str(part.get(\"Content-Disposition\"))\n",
    "                \n",
    "                if \"attachment\" not in content_disposition:\n",
    "                    if content_type == \"text/plain\":\n",
    "                        body = part.get_payload(decode=True).decode()  # Decode text\n",
    "                        break\n",
    "                    elif content_type == \"text/html\":\n",
    "                        body = part.get_payload(decode=True).decode()  # Decode HTML\n",
    "                        break\n",
    "        else:\n",
    "            body = msg.get_payload(decode=True).decode()  # For non-multipart emails\n",
    "\n",
    "        # Append data to the list\n",
    "        email_data.append({\"From\": from_, \"Subject\": subject, \"Body\": body[:200]})\n",
    "\n",
    "# Process all .eml files in the directory\n",
    "for file_name in os.listdir(email_directory):\n",
    "    if file_name.endswith(\".eml\"):\n",
    "        process_eml(os.path.join(email_directory, file_name))\n",
    "\n",
    "# Create a DataFrame from the list\n",
    "df = pd.DataFrame(email_data)\n",
    "\n",
    "# Save to CSV (optional)\n",
    "df.to_csv(\"emails.csv\", index=False)\n",
    "print(\"Data saved to emails.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e68ce8af-7116-4296-bce1-0013efaf03fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (2.2.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (4.13.4)\n",
      "Requirement already satisfied: lxml in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (5.3.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from beautifulsoup4) (4.13.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pandas beautifulsoup4 lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce363a5b-2234-4467-b1c8-fcb68203ef96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import email\n",
    "from email import policy\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Path to folder containing .eml files\n",
    "eml_folder = r\"C:\\Users\\shril\\Downloads\\Mail loads\"\n",
    "email_data = []\n",
    "\n",
    "def extract_links(body):\n",
    "    return re.findall(r'https?://\\S+', body)\n",
    "\n",
    "# Loop through each .eml file\n",
    "for filename in os.listdir(eml_folder):\n",
    "    if filename.endswith(\".eml\"):\n",
    "        with open(os.path.join(eml_folder, filename), 'r', encoding='utf-8') as f:\n",
    "            msg = email.message_from_file(f, policy=policy.default)\n",
    "\n",
    "            from_email = msg.get(\"From\")\n",
    "            to_email = msg.get(\"To\")\n",
    "            subject = msg.get(\"Subject\", \"\")\n",
    "            date = msg.get(\"Date\")\n",
    "\n",
    "            body = \"\"\n",
    "            is_html = 0\n",
    "            num_attachments = 0\n",
    "\n",
    "            for part in msg.walk():\n",
    "                content_type = part.get_content_type()\n",
    "                content_disposition = str(part.get(\"Content-Disposition\"))\n",
    "\n",
    "                if content_type == \"text/plain\" and \"attachment\" not in content_disposition:\n",
    "                    body = part.get_payload(decode=True).decode(errors='ignore')\n",
    "                elif content_type == \"text/html\":\n",
    "                    is_html = 1\n",
    "                    html = part.get_payload(decode=True).decode(errors='ignore')\n",
    "                    body = BeautifulSoup(html, \"lxml\").get_text()\n",
    "                elif \"attachment\" in content_disposition:\n",
    "                    num_attachments += 1\n",
    "\n",
    "            links = extract_links(body)\n",
    "            email_data.append({\n",
    "                \"from_email\": from_email,\n",
    "                \"to_email\": to_email,\n",
    "                \"subject\": subject,\n",
    "                \"subject_keywords\": \" \".join(subject.lower().split()[:5]),  # top 5 words\n",
    "                \"timestamp\": date,\n",
    "                \"body_text\": body[:300],  # optionally truncate\n",
    "                \"num_links\": len(links),\n",
    "                \"num_attachments\": num_attachments,\n",
    "                \"is_html\": is_html\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "037b8604-b8ae-4b21-bb44-7bc29287c767",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(email_data)\n",
    "df.to_csv(\"emails_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37d4cbb6-69b3-41b4-a7f5-008b4d90ec2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: networkx in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (3.4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ec0b5b5-b86c-4792-84e4-01580b2dfca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Graph created\n",
      "Number of nodes: 17\n",
      "Number of edges: 12\n",
      "\n",
      "Sample edges:\n",
      "Dean - Academics and IQAC <iqac@cmrit.ac.in> -> All Students <allstudents@cmrit.ac.in>, All Staff <allstaff@cmrit.ac.in>, Subject: Fwd: Subject: Call for Abstracts – Poster Presentation Awards at 3D GEM 2025 (5th Edition) | IISc Bengaluru\n",
      "Dean - Academics and IQAC <iqac@cmrit.ac.in> -> All Staff <allstaff@cmrit.ac.in>, All Students <allstudents@cmrit.ac.in>, Subject: Fwd: 🏆 CSE Students Win GCEM Hacks 2K25 Hackathon – Congratulations!\n",
      "Instructables <no-reply@mail.newsletter.instructables.com> -> shnk22aiml@cmrit.ac.in, Subject: Autonomous Home Robot\n",
      "Vice Principal CMRIT <viceprincipal@cmrit.ac.in> -> All Staff <allstaff@cmrit.ac.in>, All Students <allstudents@cmrit.ac.in>, Subject: Fwd: Cultura’25 is Here! Join the Ultimate Techno-Cultural Fest on April 25 & 26!\n",
      "Vice Principal CMRIT <viceprincipal@cmrit.ac.in> -> All Students <allstudents@cmrit.ac.in>, Subject: Fwd: circular\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Create a directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Use the correct variable name: email_data\n",
    "for email_entry in email_data:\n",
    "    from_node = email_entry[\"from_email\"]\n",
    "    to_node = email_entry[\"to_email\"]\n",
    "    subject = email_entry[\"subject\"]\n",
    "\n",
    "    if from_node and to_node:\n",
    "        # Add nodes and edge\n",
    "        G.add_node(from_node)\n",
    "        G.add_node(to_node)\n",
    "        G.add_edge(from_node, to_node, subject=subject)\n",
    "# Show graph info\n",
    "print(\"✅ Graph created\")\n",
    "print(\"Number of nodes:\", G.number_of_nodes())\n",
    "print(\"Number of edges:\", G.number_of_edges())\n",
    "\n",
    "# Show a few edges with subjects\n",
    "print(\"\\nSample edges:\")\n",
    "for u, v, d in list(G.edges(data=True))[:5]:\n",
    "    print(f\"{u} -> {v}, Subject: {d['subject']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bde6730c-5def-4ab3-a889-40afc760df18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 17\n",
      "Number of edges: 12\n",
      "Dean - Academics and IQAC <iqac@cmrit.ac.in> -> All Students <allstudents@cmrit.ac.in>, All Staff <allstaff@cmrit.ac.in>, Subject: Fwd: Subject: Call for Abstracts – Poster Presentation Awards at 3D GEM 2025 (5th Edition) | IISc Bengaluru\n",
      "Dean - Academics and IQAC <iqac@cmrit.ac.in> -> All Staff <allstaff@cmrit.ac.in>, All Students <allstudents@cmrit.ac.in>, Subject: Fwd: 🏆 CSE Students Win GCEM Hacks 2K25 Hackathon – Congratulations!\n",
      "Instructables <no-reply@mail.newsletter.instructables.com> -> shnk22aiml@cmrit.ac.in, Subject: Autonomous Home Robot\n",
      "Vice Principal CMRIT <viceprincipal@cmrit.ac.in> -> All Staff <allstaff@cmrit.ac.in>, All Students <allstudents@cmrit.ac.in>, Subject: Fwd: Cultura’25 is Here! Join the Ultimate Techno-Cultural Fest on April 25 & 26!\n",
      "Vice Principal CMRIT <viceprincipal@cmrit.ac.in> -> All Students <allstudents@cmrit.ac.in>, Subject: Fwd: circular\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of nodes:\", G.number_of_nodes())\n",
    "print(\"Number of edges:\", G.number_of_edges())\n",
    "\n",
    "# Print a few edges\n",
    "for u, v, d in list(G.edges(data=True))[:5]:\n",
    "    print(f\"{u} -> {v}, Subject: {d['subject']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e16184a9-f1e3-4148-a350-8b1dfa6c15f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved as nodes.csv and edges.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define nodes\n",
    "nodes = [\n",
    "    \"iqac@cmrit.ac.in\", \"allstudents@cmrit.ac.in\", \"allstaff@cmrit.ac.in\",\n",
    "    \"no-reply@mail.newsletter.instructables.com\", \"shnk22aiml@cmrit.ac.in\",\n",
    "    \"viceprincipal@cmrit.ac.in\"\n",
    "]\n",
    "\n",
    "# Make sure all nodes are unique\n",
    "nodes_df = pd.DataFrame({\"id\": list(set(nodes))})\n",
    "\n",
    "# Define edges (sender -> receiver)\n",
    "edges = [\n",
    "    (\"iqac@cmrit.ac.in\", \"allstudents@cmrit.ac.in\"),\n",
    "    (\"iqac@cmrit.ac.in\", \"allstaff@cmrit.ac.in\"),\n",
    "    (\"iqac@cmrit.ac.in\", \"allstaff@cmrit.ac.in\"),\n",
    "    (\"iqac@cmrit.ac.in\", \"allstudents@cmrit.ac.in\"),\n",
    "    (\"no-reply@mail.newsletter.instructables.com\", \"shnk22aiml@cmrit.ac.in\"),\n",
    "    (\"viceprincipal@cmrit.ac.in\", \"allstaff@cmrit.ac.in\"),\n",
    "    (\"viceprincipal@cmrit.ac.in\", \"allstudents@cmrit.ac.in\"),\n",
    "    (\"viceprincipal@cmrit.ac.in\", \"allstudents@cmrit.ac.in\"),\n",
    "]\n",
    "\n",
    "edges_df = pd.DataFrame(edges, columns=[\"source\", \"target\"])\n",
    "\n",
    "# Save as CSV\n",
    "nodes_df.to_csv(\"nodes.csv\", index=False)\n",
    "edges_df.to_csv(\"edges.csv\", index=False)\n",
    "\n",
    "print(\"Dataset saved as nodes.csv and edges.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cef1da7e-8604-4eb7-8dc9-20bf95ff8b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch\n",
      "  Downloading torch-2.7.0-cp311-cp311-win_amd64.whl (212.5 MB)\n",
      "     -------------------------------------- 212.5/212.5 MB 1.3 MB/s eta 0:00:00\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.22.0-cp311-cp311-win_amd64.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 1.7 MB/s eta 0:00:00\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.7.0-cp311-cp311-win_amd64.whl (2.5 MB)\n",
      "     ---------------------------------------- 2.5/2.5 MB 1.8 MB/s eta 0:00:00\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from torch) (4.13.2)\n",
      "Collecting sympy>=1.13.3\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "     ---------------------------------------- 6.3/6.3 MB 1.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: networkx in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from torchvision) (2.2.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from torchvision) (11.2.1)\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "     -------------------------------------- 536.2/536.2 kB 1.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Installing collected packages: mpmath, sympy, filelock, torch, torchvision, torchaudio\n",
      "Successfully installed filelock-3.18.0 mpmath-1.3.0 sympy-1.14.0 torch-2.7.0 torchaudio-2.7.0 torchvision-0.22.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script isympy.exe is installed in 'C:\\Users\\shril\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts torchfrtrace.exe and torchrun.exe are installed in 'C:\\Users\\shril\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch-geometric\n",
      "  Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
      "     ---------------------------------------- 1.1/1.1 MB 1.6 MB/s eta 0:00:00\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.11.18-cp311-cp311-win_amd64.whl (443 kB)\n",
      "     -------------------------------------- 443.7/443.7 kB 1.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: fsspec in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from torch-geometric) (2025.3.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from torch-geometric) (3.1.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from torch-geometric) (2.2.5)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from torch-geometric) (7.0.0)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from torch-geometric) (3.2.3)\n",
      "Requirement already satisfied: requests in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from torch-geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from torch-geometric) (4.67.1)\n",
      "Collecting aiohappyeyeballs>=2.3.0\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp->torch-geometric) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.6.0-cp311-cp311-win_amd64.whl (120 kB)\n",
      "     -------------------------------------- 120.9/120.9 kB 1.4 MB/s eta 0:00:00\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.4.3-cp311-cp311-win_amd64.whl (38 kB)\n",
      "Collecting propcache>=0.2.0\n",
      "  Downloading propcache-0.3.1-cp311-cp311-win_amd64.whl (45 kB)\n",
      "     ---------------------------------------- 45.2/45.2 kB 1.1 MB/s eta 0:00:00\n",
      "Collecting yarl<2.0,>=1.17.0\n",
      "  Downloading yarl-1.20.0-cp311-cp311-win_amd64.whl (93 kB)\n",
      "     ---------------------------------------- 93.4/93.4 kB 2.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->torch-geometric) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from requests->torch-geometric) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from requests->torch-geometric) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from requests->torch-geometric) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from requests->torch-geometric) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->torch-geometric) (0.4.6)\n",
      "Installing collected packages: propcache, multidict, frozenlist, aiohappyeyeballs, yarl, aiosignal, aiohttp, torch-geometric\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.11.18 aiosignal-1.3.2 frozenlist-1.6.0 multidict-6.4.3 propcache-0.3.1 torch-geometric-2.6.1 yarl-1.20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio\n",
    "!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a76b11e-51f0-499a-a4d7-9b8809f5f862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Node features saved to features.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert email_data to DataFrame\n",
    "df = pd.DataFrame(email_data)\n",
    "\n",
    "# Group by sender and calculate features\n",
    "features = df.groupby(\"from_email\").agg({\n",
    "    \"num_links\": \"mean\",\n",
    "    \"num_attachments\": \"mean\",\n",
    "    \"is_html\": \"mean\",\n",
    "    \"subject\": \"count\"\n",
    "}).rename(columns={\"subject\": \"email_count\"})\n",
    "\n",
    "features.reset_index(inplace=True)\n",
    "features.rename(columns={\"from_email\": \"id\"}, inplace=True)\n",
    "features.to_csv(\"features.csv\", index=False)\n",
    "\n",
    "print(\"✅ Node features saved to features.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e3b0db1-70b2-47f2-b1bb-f0074e60fcfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels saved to labels.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Example list of emails and their labels (0 for legit, 1 for phishing)\n",
    "emails = [\n",
    "    {\"id\": \"iqac@cmrit.ac.in\", \"label\": 0},\n",
    "    {\"id\": \"viceprincipal@cmrit.ac.in\", \"label\": 0},\n",
    "    {\"id\": \"no-reply@mail.newsletter.instructables.com\", \"label\": 1},\n",
    "    {\"id\": \"randomphisher@badmail.com\", \"label\": 1}\n",
    "]\n",
    "\n",
    "# Define the output file name\n",
    "output_file = \"labels.csv\"\n",
    "\n",
    "# Write to CSV\n",
    "with open(output_file, mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=[\"id\", \"label\"])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(emails)\n",
    "\n",
    "print(f\"Labels saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1087f108-0eae-422d-bb3e-b9666545353d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 4)) while a minimum of 1 is required by StandardScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m----------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     26\u001b[39m features_df = features_df.dropna(subset=[\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m])  \u001b[38;5;66;03m# Drop rows with NaN ID after mapping\u001b[39;00m\n\u001b[32m     27\u001b[39m features_df = features_df.sort_values(\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     28\u001b[39m x = torch.tensor(\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     \u001b[43mStandardScaler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mid\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m     30\u001b[39m     dtype=torch.float\n\u001b[32m     31\u001b[39m )\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# 5. Prepare labels (ensure they align with features)\u001b[39;00m\n\u001b[32m     34\u001b[39m labels_df[\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m] = labels_df[\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m].map(id_map)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    321\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    322\u001b[39m         return_tuple = (\n\u001b[32m    323\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    324\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    325\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:918\u001b[39m, in \u001b[36mTransformerMixin.fit_transform\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    903\u001b[39m         warnings.warn(\n\u001b[32m    904\u001b[39m             (\n\u001b[32m    905\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) has a `transform`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    913\u001b[39m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[32m    914\u001b[39m         )\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    917\u001b[39m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m.transform(X)\n\u001b[32m    919\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    920\u001b[39m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fit(X, y, **fit_params).transform(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\preprocessing\\_data.py:894\u001b[39m, in \u001b[36mStandardScaler.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    892\u001b[39m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[32m    893\u001b[39m \u001b[38;5;28mself\u001b[39m._reset()\n\u001b[32m--> \u001b[39m\u001b[32m894\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\preprocessing\\_data.py:930\u001b[39m, in \u001b[36mStandardScaler.partial_fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    898\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[32m    899\u001b[39m \n\u001b[32m    900\u001b[39m \u001b[33;03mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    927\u001b[39m \u001b[33;03m    Fitted scaler.\u001b[39;00m\n\u001b[32m    928\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    929\u001b[39m first_call = \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mn_samples_seen_\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m930\u001b[39m X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfirst_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    938\u001b[39m n_features = X.shape[\u001b[32m1\u001b[39m]\n\u001b[32m    940\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2944\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2942\u001b[39m         out = X, y\n\u001b[32m   2943\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2944\u001b[39m     out = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2945\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2946\u001b[39m     out = _check_y(y, **check_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:1130\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1128\u001b[39m     n_samples = _num_samples(array)\n\u001b[32m   1129\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_samples < ensure_min_samples:\n\u001b[32m-> \u001b[39m\u001b[32m1130\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1131\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m) while a\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1132\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1133\u001b[39m             % (n_samples, array.shape, ensure_min_samples, context)\n\u001b[32m   1134\u001b[39m         )\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array.ndim == \u001b[32m2\u001b[39m:\n\u001b[32m   1137\u001b[39m     n_features = array.shape[\u001b[32m1\u001b[39m]\n",
      "\u001b[31mValueError\u001b[39m: Found array with 0 sample(s) (shape=(0, 4)) while a minimum of 1 is required by StandardScaler."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# 1. Load CSVs\n",
    "nodes_df = pd.read_csv('nodes.csv')\n",
    "edges_df = pd.read_csv('edges.csv')\n",
    "features_df = pd.read_csv('features.csv')\n",
    "labels_df = pd.read_csv('labels.csv')  # Optional\n",
    "\n",
    "# 2. Encode node IDs as integers\n",
    "le = LabelEncoder()\n",
    "nodes_df['node_idx'] = le.fit_transform(nodes_df['id'])\n",
    "id_map = dict(zip(nodes_df['id'], nodes_df['node_idx']))\n",
    "\n",
    "# 3. Create edge index (tensor)\n",
    "edges_df['source'] = edges_df['source'].map(id_map)\n",
    "edges_df['target'] = edges_df['target'].map(id_map)\n",
    "edges_df = edges_df.dropna()  # Remove unmapped edges\n",
    "edge_index = torch.tensor(edges_df[['source', 'target']].values.T, dtype=torch.long)\n",
    "\n",
    "# 4. Prepare node features\n",
    "features_df['id'] = features_df['id'].map(id_map)\n",
    "features_df = features_df.dropna(subset=['id'])  # Drop rows with NaN ID after mapping\n",
    "features_df = features_df.sort_values('id')\n",
    "x = torch.tensor(\n",
    "    StandardScaler().fit_transform(features_df.drop(columns='id').values),\n",
    "    dtype=torch.float\n",
    ")\n",
    "\n",
    "# 5. Prepare labels (ensure they align with features)\n",
    "labels_df['id'] = labels_df['id'].map(id_map)\n",
    "labels_df = labels_df.dropna(subset=['id'])  # Drop unmapped\n",
    "labels_df = labels_df.sort_values('id')\n",
    "\n",
    "# Align labels to feature nodes only\n",
    "merged_df = pd.merge(features_df, labels_df, on='id', how='inner')\n",
    "x = torch.tensor(\n",
    "    StandardScaler().fit_transform(merged_df.drop(columns=['id', 'label']).values),\n",
    "    dtype=torch.float\n",
    ")\n",
    "y = torch.tensor(merged_df['label'].values, dtype=torch.long)\n",
    "\n",
    "# 6. Build PyG Data object\n",
    "data = Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "# 7. Define a simple GNN\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# 8. Train the GNN\n",
    "model = GCN(input_dim=x.shape[1], hidden_dim=16, output_dim=2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "model.train()\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = criterion(out, data.y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}: Loss = {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf22240-522a-41e0-b46a-6a72638c8ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
