{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "051f3de7-2b79-446f-9b5f-6444e1c54b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: extract-msg in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (0.54.1)\n",
      "Requirement already satisfied: olefile==0.47 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from extract-msg) (0.47)\n",
      "Requirement already satisfied: tzlocal<6,>=4.2 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from extract-msg) (5.3.1)\n",
      "Requirement already satisfied: compressed-rtf<2,>=1.0.6 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from extract-msg) (1.0.7)\n",
      "Requirement already satisfied: ebcdic<2,>=1.1.1 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from extract-msg) (1.1.1)\n",
      "Requirement already satisfied: beautifulsoup4<4.14,>=4.11.1 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from extract-msg) (4.13.4)\n",
      "Requirement already satisfied: RTFDE<0.2,>=0.1.1 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from extract-msg) (0.1.2)\n",
      "Requirement already satisfied: red-black-tree-mod<=1.23,>=1.20 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from extract-msg) (1.22)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from beautifulsoup4<4.14,>=4.11.1->extract-msg) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from beautifulsoup4<4.14,>=4.11.1->extract-msg) (4.13.2)\n",
      "Requirement already satisfied: lark~=1.1.8 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from RTFDE<0.2,>=0.1.1->extract-msg) (1.1.9)\n",
      "Requirement already satisfied: oletools>=0.56 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from RTFDE<0.2,>=0.1.1->extract-msg) (0.60.2)\n",
      "Requirement already satisfied: tzdata in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from tzlocal<6,>=4.2->extract-msg) (2025.2)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from oletools>=0.56->RTFDE<0.2,>=0.1.1->extract-msg) (3.2.3)\n",
      "Requirement already satisfied: easygui in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from oletools>=0.56->RTFDE<0.2,>=0.1.1->extract-msg) (0.98.3)\n",
      "Requirement already satisfied: colorclass in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from oletools>=0.56->RTFDE<0.2,>=0.1.1->extract-msg) (2.2.2)\n",
      "Requirement already satisfied: pcodedmp>=1.2.5 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from oletools>=0.56->RTFDE<0.2,>=0.1.1->extract-msg) (1.2.6)\n",
      "Requirement already satisfied: msoffcrypto-tool in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from oletools>=0.56->RTFDE<0.2,>=0.1.1->extract-msg) (5.4.2)\n",
      "Requirement already satisfied: win-unicode-console in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from pcodedmp>=1.2.5->oletools>=0.56->RTFDE<0.2,>=0.1.1->extract-msg) (0.5)\n",
      "Requirement already satisfied: cryptography>=39.0 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from msoffcrypto-tool->oletools>=0.56->RTFDE<0.2,>=0.1.1->extract-msg) (44.0.2)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from cryptography>=39.0->msoffcrypto-tool->oletools>=0.56->RTFDE<0.2,>=0.1.1->extract-msg) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from cffi>=1.12->cryptography>=39.0->msoffcrypto-tool->oletools>=0.56->RTFDE<0.2,>=0.1.1->extract-msg) (2.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install extract-msg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2fc90d4-deae-4a28-9cc8-8534890756a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import extract_msg\n",
    "\n",
    "input_folder = r\"C:\\Users\\shril\\Downloads\\Mail loads\"\n",
    "output_folder = r\"/MAJOR PROJECT/mail op msg\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.endswith(\".msg\"):\n",
    "        msg = extract_msg.Message(os.path.join(input_folder, filename))\n",
    "        with open(os.path.join(output_folder, filename.replace('.msg', '.eml')), 'w', encoding='utf-8') as f:\n",
    "            f.write(msg.as_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5449b790-06d3-44ef-a091-3d7f19830455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\shril\\MAJOR PROJECT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "93b444d1-3e9a-4601-9f56-dca0b54413c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: Dean - Academics and IQAC <iqac@cmrit.ac.in>\n",
      "Subject: Fwd: Applications Open: DMP 2025 Open-Source Mentorship Program | PPO\n",
      " for Top Performers\n",
      "Body: ---------- Forwarded message ---------\n",
      "From: Poonam Tijare <director.placement@cmrit.ac.in>\n",
      "Date: Wed, Apr 23, 2025 at 8:08‚ÄØPM\n",
      "Subject: Fwd: Applications Open: DMP 2025 Open-Source Mentorship Progr...\n",
      "--------------------------------------------------\n",
      "From: Instructables <no-reply@mail.newsletter.instructables.com>\n",
      "Subject: Autonomous Home Robot\n",
      "Body: <html xmlns=\"http://www.w3.org/1999/xhtml\"><head><meta content=\"text/html; charset=utf-8\" http-equiv=\"Content-Type\"/><meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/><meta conten...\n",
      "--------------------------------------------------\n",
      "From: Vice Principal CMRIT <viceprincipal@cmrit.ac.in>\n",
      "Subject: Fwd: Cultura‚Äô25 is Here! Join the Ultimate Techno-Cultural Fest on April 25 & 26!\n",
      "Body: Dr B Narasimha Murthy\n",
      "Vice Principal, CMRIT\n",
      "Bangalore\n",
      "\n",
      "---------- Forwarded message ---------\n",
      "From: Kashif Ahmed <kashif.a@cmrit.ac.in>\n",
      "Date: Thu, Apr 24, 2025, 8:29‚ÄØPM\n",
      "Subject: Fwd: Cultura‚Äô25...\n",
      "--------------------------------------------------\n",
      "From: Dean - Academics and IQAC <iqac@cmrit.ac.in>\n",
      "Subject: Fwd: Field Visit and Participation in Awareness Conclave on Assistive\n",
      " Technology 2025\n",
      "Body: Congratulations Srijan S K and other team members!\n",
      "\n",
      "---------- Forwarded message ---------\n",
      "From: Dr.Pappa .M <hod.ece@cmrit.ac.in>\n",
      "Date: Wed, 16 Apr 2025, 7:43 pm\n",
      "Subject: Fwd: Field Visit and Pa...\n",
      "--------------------------------------------------\n",
      "From: Dean - Academics and IQAC <iqac@cmrit.ac.in>\n",
      "Subject: Fwd: BGSCET Bengaluru SAMVIT Fest\n",
      "Body: \n",
      "---------- Forwarded message ---------\n",
      "From: Dr.K. Meenakshi <hod.maths@cmrit.ac.in<mailto:hod.maths@cmrit.ac.in>>\n",
      "Date: Thu, 1 May 2025, 12:53 pm\n",
      "Subject: BGSCET Bengaluru SAMVIT Fest\n",
      "To: Dean ...\n",
      "--------------------------------------------------\n",
      "From: Dean - Academics and IQAC <iqac@cmrit.ac.in>\n",
      "Subject: Fwd: Call for papers | BAIN-2025, International Conference on\n",
      " Business Analytics and intelligence (Hybrid mode)\n",
      "Body: \n",
      "\n",
      "---------- Forwarded message ---------\n",
      "From: Dr. M. Sandeep Kumar <hod.mba@cmrit.ac.in<mailto:hod.mba@cmrit.ac.in>>\n",
      "Date: Mon, Apr 28, 2025 at 4:18‚ÄØPM\n",
      "Subject: Fwd: Call for papers | BAIN-2025,...\n",
      "--------------------------------------------------\n",
      "From: Vice Principal CMRIT <viceprincipal@cmrit.ac.in>\n",
      "Subject: Fwd: circular\n",
      "Body: \n",
      "\n",
      "Dr B Narasimha Murthy\n",
      "Vice Principal, CMRIT\n",
      "Bangalore\n",
      "\n",
      "---------- Forwarded message ---------\n",
      "From: Dr. Sanjay Jain <principal@cmrit.ac.in<mailto:principal@cmrit.ac.in>>\n",
      "Date: Mon, Apr 28, 2...\n",
      "--------------------------------------------------\n",
      "From: Dean - Academics and IQAC <iqac@cmrit.ac.in>\n",
      "Subject: Fwd: Google Women Techmakers event\n",
      "Body: ---------- Forwarded message ---------\n",
      "From: Dr. Jagadishwari V <hod.ise@cmrit.ac.in<mailto:hod.ise@cmrit.ac.in>>\n",
      "Date: Fri, May 2, 2025 at 1:43‚ÄØPM\n",
      "Subject: Google Women Techmakers event\n",
      "To: Dean ...\n",
      "--------------------------------------------------\n",
      "From: Dean - Academics and IQAC <iqac@cmrit.ac.in>\n",
      "Subject: Fwd: VTU-CPC- Hackathon - Pace Wisdom\n",
      "Body: \n",
      "---------- Forwarded message ---------\n",
      "From: Poonam Tijare <director.placement@cmrit.ac.in<mailto:director.placement@cmrit.ac.in>>\n",
      "Date: Fri, 2 May 2025, 4:17 pm\n",
      "Subject: Fwd: VTU-CPC- Hackathon ...\n",
      "--------------------------------------------------\n",
      "From: Kavitha Campus House <hostel@cmrit.ac.in>\n",
      "Subject: Introduction of SPACE BASIC APP\n",
      "Body: Dear Students,\n",
      "\n",
      "To enhance the overall hostel experience and streamline administrative\n",
      "processes, we are pleased to introduce *Space Basic* ‚Äì a comprehensive Hostel\n",
      "Management Application designed...\n",
      "--------------------------------------------------\n",
      "From: Udemy <hello@students.udemy.com>\n",
      "Subject: It‚Äôs the last day of our sale. Shop now and save.\n",
      "Body: \n",
      "Courses are on sale today. See the ones other learners are ranking the best.\n",
      "Õè ‚Äå   ‚Äá Ôªø Õè ‚Äå   ‚Äá Ôªø Õè ‚Äå   ‚Äá Ôªø Õè ‚Äå   ‚Äá Ôªø Õè ‚Äå   ‚Äá Ôªø Õè ‚Äå   ‚Äá Ôªø Õè ‚Äå   ‚Äá Ôªø Õè ‚Äå   ‚Äá Ôªø Õè ‚Äå   ‚Äá Ôªø Õè ‚Äå   ‚Äá Ôªø Õè ‚Äå   ‚Äá Ôªø Õè ‚Äå   ‚Äá Ôªø ...\n",
      "--------------------------------------------------\n",
      "From: rakuten-product-conference@mail.rakuten.com\n",
      "Subject: Keep the Vibe Alive! Join to Attend Final Sessions of RPC 2025! üöÄ\n",
      "Body: <html><head>\n",
      "<meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\"><style>\n",
      "        body { font-family: Rakuten Sans, sans-serif; font-size:11pt;}\n",
      "        .header { color: #0082cc; }\n",
      "    ...\n",
      "--------------------------------------------------\n",
      "From: Coursera <Coursera@m.learn.coursera.org>\n",
      "Subject: Learn AI product management from Microsoft üöÄ\n",
      "Body: \n",
      "Finish this beginner-level program in just three months.\n",
      "Õè ‚Äå   ‚Äá Ôªø Õè ‚Äå   ‚Äá Ôªø Õè ‚Äå   ‚Äá Ôªø Õè ‚Äå   ‚Äá Ôªø Õè ‚Äå   ‚Äá Ôªø Õè ‚Äå   ‚Äá Ôªø Õè ‚Äå   ‚Äá Ôªø Õè ‚Äå   ‚Äá Ôªø Õè ‚Äå   ‚Äá Ôªø Õè ‚Äå   ‚Äá Ôªø Õè ‚Äå   ‚Äá Ôªø Õè ‚Äå   ‚Äá Ôªø Õè ‚Äå   ‚Äá Ôªø Õè ‚Äå   ‚Äá Ôªø ...\n",
      "--------------------------------------------------\n",
      "From: LeetCode <no-reply@leetcode.com>\n",
      "Subject: LeetCode Weekly Digest\n",
      "Body: [LeetCode]\n",
      "Hi LeetCoder!\n",
      "Choosing between big tech stability and a fast-paced startup isn‚Äôt easy. This LeetCoder is weighing Microsoft L61 vs 6sense SDE, and their post highlights what really matter...\n",
      "--------------------------------------------------\n",
      "From: Dean - Academics and IQAC <iqac@cmrit.ac.in>\n",
      "Subject: Fwd: PARKING VENUE FOR CULTURA'25 FEST\n",
      "Body: ---------- Forwarded message ---------\n",
      "From: Kashif Ahmed <kashif.a@cmrit.ac.in>\n",
      "Date: Thu, Apr 24, 2025 at 3:02‚ÄØPM\n",
      "Subject: PARKING VENUE FOR CULTURA'25 FEST\n",
      "To: Dean - Academics and IQAC <iqac@c...\n",
      "--------------------------------------------------\n",
      "From: Dean - Academics and IQAC <iqac@cmrit.ac.in>\n",
      "Subject: Fwd: Pusa Krishi Startup Grant-in-Aid Incubation Program 2025-For\n",
      " Startups and Students\n",
      "Body: ---------- Forwarded message ---------\n",
      "From: CMRIT . <info@cmrit.ac.in>\n",
      "Date: Wed, Apr 16, 2025 at 2:11‚ÄØPM\n",
      "Subject: Fwd: Pusa Krishi Startup Grant-in-Aid Incubation Program 2025-For\n",
      "Startups and S...\n",
      "--------------------------------------------------\n",
      "From: \"HackerEarth\" <community_marketing@hackerearth.com>\n",
      "Subject: SmartQ is hiring!\n",
      "Body: HackerEarth\n",
      "[https://img.mmdocdn.com/mailmodo/image/upload/ar_403:77,c_crop/v1637750530/editor/p/76e3b4d2-d919-439a-a73d-33052ecba42b/bfd858131613260f8173e5091c578c00_uhzoic.png]https://t.mmtrkr.com/c...\n",
      "--------------------------------------------------\n",
      "From: Dean - Academics and IQAC <iqac@cmrit.ac.in>\n",
      "Subject: Fwd: Subject: Call for Abstracts ‚Äì Poster Presentation Awards at 3D GEM 2025 (5th Edition) | IISc Bengaluru\n",
      "Body: ---------- Forwarded message ---------\n",
      "From: msreddy@3dgraphy.in <msreddy@3dgraphy.in>\n",
      "Date: Thu, Apr 24, 2025 at 1:06‚ÄØPM\n",
      "Subject: Subject: Call for Abstracts ‚Äì Poster Presentation Awards at 3D GEM...\n",
      "--------------------------------------------------\n",
      "From: Dean - Academics and IQAC <iqac@cmrit.ac.in>\n",
      "Subject: Fwd: üèÜ CSE Students Win GCEM Hacks 2K25 Hackathon ‚Äì Congratulations!\n",
      "Body: Hearty Congratulations Tarun Prakash Jha, Ronish Rohan, Kavin and Prof.\n",
      "Navaneetha!!\n",
      "\n",
      "---------- Forwarded message ---------\n",
      "From: Dr.Kesavamoorthy-HoD-CSE <hod.cse@cmrit.ac.in>\n",
      "Date: Tue, Apr 29...\n",
      "--------------------------------------------------\n",
      "From: Agnirva.com <Student@agnirva.com>\n",
      "Subject: üì≤Future Software Dev? This Internship Is Your Launchpad\n",
      "Body: \n",
      "Code, Build, Win ‚Äì Your Internship Journey Starts Here‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ‚Äå ...\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import email\n",
    "import os\n",
    "\n",
    "# Specify the directory where your .eml files are saved\n",
    "email_directory = \"C:\\\\Users\\\\shril\\\\Downloads\\\\Mail loads\"  # Change to your folder\n",
    "\n",
    "# Function to process .eml files\n",
    "def process_eml(file_path):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        msg = email.message_from_bytes(f.read())\n",
    "        \n",
    "        # Extract subject and sender\n",
    "        subject, encoding = email.header.decode_header(msg[\"Subject\"])[0]\n",
    "        if isinstance(subject, bytes):\n",
    "            subject = subject.decode(encoding or \"utf-8\")\n",
    "        \n",
    "        from_ = msg.get(\"From\")\n",
    "        \n",
    "        # Extract body (plain text or HTML)\n",
    "        body = \"\"\n",
    "        if msg.is_multipart():\n",
    "            for part in msg.walk():\n",
    "                content_type = part.get_content_type()\n",
    "                content_disposition = str(part.get(\"Content-Disposition\"))\n",
    "                \n",
    "                if \"attachment\" not in content_disposition:\n",
    "                    if content_type == \"text/plain\":\n",
    "                        body = part.get_payload(decode=True).decode()  # Decode text\n",
    "                        break\n",
    "                    elif content_type == \"text/html\":\n",
    "                        body = part.get_payload(decode=True).decode()  # Decode HTML\n",
    "                        break\n",
    "        else:\n",
    "            body = msg.get_payload(decode=True).decode()  # For non-multipart emails\n",
    "\n",
    "        # Print extracted information\n",
    "        print(f\"From: {from_}\")\n",
    "        print(f\"Subject: {subject}\")\n",
    "        print(f\"Body: {body[:200]}...\")  # Print first 200 chars of body\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "# Process all .eml files in the directory\n",
    "for file_name in os.listdir(email_directory):\n",
    "    if file_name.endswith(\".eml\"):\n",
    "        process_eml(os.path.join(email_directory, file_name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55a7063b-5b11-4b7b-a1ed-e24c0a458bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to emails.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty list to store email data\n",
    "email_data = []\n",
    "\n",
    "# Modify the process function to store data\n",
    "def process_eml(file_path):\n",
    "    with open(file_path, \"rb\") as f:\n",
    "        msg = email.message_from_bytes(f.read())\n",
    "        \n",
    "        # Extract information\n",
    "        subject, encoding = email.header.decode_header(msg[\"Subject\"])[0]\n",
    "        if isinstance(subject, bytes):\n",
    "            subject = subject.decode(encoding or \"utf-8\")\n",
    "        \n",
    "        from_ = msg.get(\"From\")\n",
    "        body = \"\"\n",
    "        if msg.is_multipart():\n",
    "            for part in msg.walk():\n",
    "                content_type = part.get_content_type()\n",
    "                content_disposition = str(part.get(\"Content-Disposition\"))\n",
    "                \n",
    "                if \"attachment\" not in content_disposition:\n",
    "                    if content_type == \"text/plain\":\n",
    "                        body = part.get_payload(decode=True).decode()  # Decode text\n",
    "                        break\n",
    "                    elif content_type == \"text/html\":\n",
    "                        body = part.get_payload(decode=True).decode()  # Decode HTML\n",
    "                        break\n",
    "        else:\n",
    "            body = msg.get_payload(decode=True).decode()  # For non-multipart emails\n",
    "\n",
    "        # Append data to the list\n",
    "        email_data.append({\"From\": from_, \"Subject\": subject, \"Body\": body[:200]})\n",
    "\n",
    "# Process all .eml files in the directory\n",
    "for file_name in os.listdir(email_directory):\n",
    "    if file_name.endswith(\".eml\"):\n",
    "        process_eml(os.path.join(email_directory, file_name))\n",
    "\n",
    "# Create a DataFrame from the list\n",
    "df = pd.DataFrame(email_data)\n",
    "\n",
    "# Save to CSV (optional)\n",
    "df.to_csv(\"emails.csv\", index=False)\n",
    "print(\"Data saved to emails.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e68ce8af-7116-4296-bce1-0013efaf03fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pandas in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (2.2.3)\n",
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (4.13.4)\n",
      "Requirement already satisfied: lxml in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (5.3.2)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from beautifulsoup4) (2.6)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from beautifulsoup4) (4.13.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install pandas beautifulsoup4 lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce363a5b-2234-4467-b1c8-fcb68203ef96",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import email\n",
    "from email import policy\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# Path to folder containing .eml files\n",
    "eml_folder = r\"C:\\Users\\shril\\Downloads\\Mail loads\"\n",
    "email_data = []\n",
    "\n",
    "def extract_links(body):\n",
    "    return re.findall(r'https?://\\S+', body)\n",
    "\n",
    "# Loop through each .eml file\n",
    "for filename in os.listdir(eml_folder):\n",
    "    if filename.endswith(\".eml\"):\n",
    "        with open(os.path.join(eml_folder, filename), 'r', encoding='utf-8') as f:\n",
    "            msg = email.message_from_file(f, policy=policy.default)\n",
    "\n",
    "            from_email = msg.get(\"From\")\n",
    "            to_email = msg.get(\"To\")\n",
    "            subject = msg.get(\"Subject\", \"\")\n",
    "            date = msg.get(\"Date\")\n",
    "\n",
    "            body = \"\"\n",
    "            is_html = 0\n",
    "            num_attachments = 0\n",
    "\n",
    "            for part in msg.walk():\n",
    "                content_type = part.get_content_type()\n",
    "                content_disposition = str(part.get(\"Content-Disposition\"))\n",
    "\n",
    "                if content_type == \"text/plain\" and \"attachment\" not in content_disposition:\n",
    "                    body = part.get_payload(decode=True).decode(errors='ignore')\n",
    "                elif content_type == \"text/html\":\n",
    "                    is_html = 1\n",
    "                    html = part.get_payload(decode=True).decode(errors='ignore')\n",
    "                    body = BeautifulSoup(html, \"lxml\").get_text()\n",
    "                elif \"attachment\" in content_disposition:\n",
    "                    num_attachments += 1\n",
    "\n",
    "            links = extract_links(body)\n",
    "            email_data.append({\n",
    "                \"from_email\": from_email,\n",
    "                \"to_email\": to_email,\n",
    "                \"subject\": subject,\n",
    "                \"subject_keywords\": \" \".join(subject.lower().split()[:5]),  # top 5 words\n",
    "                \"timestamp\": date,\n",
    "                \"body_text\": body[:300],  # optionally truncate\n",
    "                \"num_links\": len(links),\n",
    "                \"num_attachments\": num_attachments,\n",
    "                \"is_html\": is_html\n",
    "            })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "037b8604-b8ae-4b21-bb44-7bc29287c767",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(email_data)\n",
    "df.to_csv(\"emails_features.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37d4cbb6-69b3-41b4-a7f5-008b4d90ec2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: networkx in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (3.4.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install networkx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ec0b5b5-b86c-4792-84e4-01580b2dfca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Graph created\n",
      "Number of nodes: 17\n",
      "Number of edges: 12\n",
      "\n",
      "Sample edges:\n",
      "Dean - Academics and IQAC <iqac@cmrit.ac.in> -> All Students <allstudents@cmrit.ac.in>, All Staff <allstaff@cmrit.ac.in>, Subject: Fwd: Subject: Call for Abstracts ‚Äì Poster Presentation Awards at 3D GEM 2025 (5th Edition) | IISc Bengaluru\n",
      "Dean - Academics and IQAC <iqac@cmrit.ac.in> -> All Staff <allstaff@cmrit.ac.in>, All Students <allstudents@cmrit.ac.in>, Subject: Fwd: üèÜ CSE Students Win GCEM Hacks 2K25 Hackathon ‚Äì Congratulations!\n",
      "Instructables <no-reply@mail.newsletter.instructables.com> -> shnk22aiml@cmrit.ac.in, Subject: Autonomous Home Robot\n",
      "Vice Principal CMRIT <viceprincipal@cmrit.ac.in> -> All Staff <allstaff@cmrit.ac.in>, All Students <allstudents@cmrit.ac.in>, Subject: Fwd: Cultura‚Äô25 is Here! Join the Ultimate Techno-Cultural Fest on April 25 & 26!\n",
      "Vice Principal CMRIT <viceprincipal@cmrit.ac.in> -> All Students <allstudents@cmrit.ac.in>, Subject: Fwd: circular\n"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "# Create a directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Use the correct variable name: email_data\n",
    "for email_entry in email_data:\n",
    "    from_node = email_entry[\"from_email\"]\n",
    "    to_node = email_entry[\"to_email\"]\n",
    "    subject = email_entry[\"subject\"]\n",
    "\n",
    "    if from_node and to_node:\n",
    "        # Add nodes and edge\n",
    "        G.add_node(from_node)\n",
    "        G.add_node(to_node)\n",
    "        G.add_edge(from_node, to_node, subject=subject)\n",
    "# Show graph info\n",
    "print(\"‚úÖ Graph created\")\n",
    "print(\"Number of nodes:\", G.number_of_nodes())\n",
    "print(\"Number of edges:\", G.number_of_edges())\n",
    "\n",
    "# Show a few edges with subjects\n",
    "print(\"\\nSample edges:\")\n",
    "for u, v, d in list(G.edges(data=True))[:5]:\n",
    "    print(f\"{u} -> {v}, Subject: {d['subject']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bde6730c-5def-4ab3-a889-40afc760df18",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes: 17\n",
      "Number of edges: 12\n",
      "Dean - Academics and IQAC <iqac@cmrit.ac.in> -> All Students <allstudents@cmrit.ac.in>, All Staff <allstaff@cmrit.ac.in>, Subject: Fwd: Subject: Call for Abstracts ‚Äì Poster Presentation Awards at 3D GEM 2025 (5th Edition) | IISc Bengaluru\n",
      "Dean - Academics and IQAC <iqac@cmrit.ac.in> -> All Staff <allstaff@cmrit.ac.in>, All Students <allstudents@cmrit.ac.in>, Subject: Fwd: üèÜ CSE Students Win GCEM Hacks 2K25 Hackathon ‚Äì Congratulations!\n",
      "Instructables <no-reply@mail.newsletter.instructables.com> -> shnk22aiml@cmrit.ac.in, Subject: Autonomous Home Robot\n",
      "Vice Principal CMRIT <viceprincipal@cmrit.ac.in> -> All Staff <allstaff@cmrit.ac.in>, All Students <allstudents@cmrit.ac.in>, Subject: Fwd: Cultura‚Äô25 is Here! Join the Ultimate Techno-Cultural Fest on April 25 & 26!\n",
      "Vice Principal CMRIT <viceprincipal@cmrit.ac.in> -> All Students <allstudents@cmrit.ac.in>, Subject: Fwd: circular\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of nodes:\", G.number_of_nodes())\n",
    "print(\"Number of edges:\", G.number_of_edges())\n",
    "\n",
    "# Print a few edges\n",
    "for u, v, d in list(G.edges(data=True))[:5]:\n",
    "    print(f\"{u} -> {v}, Subject: {d['subject']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e16184a9-f1e3-4148-a350-8b1dfa6c15f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved as nodes.csv and edges.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Define nodes\n",
    "nodes = [\n",
    "    \"iqac@cmrit.ac.in\", \"allstudents@cmrit.ac.in\", \"allstaff@cmrit.ac.in\",\n",
    "    \"no-reply@mail.newsletter.instructables.com\", \"shnk22aiml@cmrit.ac.in\",\n",
    "    \"viceprincipal@cmrit.ac.in\"\n",
    "]\n",
    "\n",
    "# Make sure all nodes are unique\n",
    "nodes_df = pd.DataFrame({\"id\": list(set(nodes))})\n",
    "\n",
    "# Define edges (sender -> receiver)\n",
    "edges = [\n",
    "    (\"iqac@cmrit.ac.in\", \"allstudents@cmrit.ac.in\"),\n",
    "    (\"iqac@cmrit.ac.in\", \"allstaff@cmrit.ac.in\"),\n",
    "    (\"iqac@cmrit.ac.in\", \"allstaff@cmrit.ac.in\"),\n",
    "    (\"iqac@cmrit.ac.in\", \"allstudents@cmrit.ac.in\"),\n",
    "    (\"no-reply@mail.newsletter.instructables.com\", \"shnk22aiml@cmrit.ac.in\"),\n",
    "    (\"viceprincipal@cmrit.ac.in\", \"allstaff@cmrit.ac.in\"),\n",
    "    (\"viceprincipal@cmrit.ac.in\", \"allstudents@cmrit.ac.in\"),\n",
    "    (\"viceprincipal@cmrit.ac.in\", \"allstudents@cmrit.ac.in\"),\n",
    "]\n",
    "\n",
    "edges_df = pd.DataFrame(edges, columns=[\"source\", \"target\"])\n",
    "\n",
    "# Save as CSV\n",
    "nodes_df.to_csv(\"nodes.csv\", index=False)\n",
    "edges_df.to_csv(\"edges.csv\", index=False)\n",
    "\n",
    "print(\"Dataset saved as nodes.csv and edges.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cef1da7e-8604-4eb7-8dc9-20bf95ff8b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch\n",
      "  Downloading torch-2.7.0-cp311-cp311-win_amd64.whl (212.5 MB)\n",
      "     -------------------------------------- 212.5/212.5 MB 1.3 MB/s eta 0:00:00\n",
      "Collecting torchvision\n",
      "  Downloading torchvision-0.22.0-cp311-cp311-win_amd64.whl (1.7 MB)\n",
      "     ---------------------------------------- 1.7/1.7 MB 1.7 MB/s eta 0:00:00\n",
      "Collecting torchaudio\n",
      "  Downloading torchaudio-2.7.0-cp311-cp311-win_amd64.whl (2.5 MB)\n",
      "     ---------------------------------------- 2.5/2.5 MB 1.8 MB/s eta 0:00:00\n",
      "Collecting filelock\n",
      "  Downloading filelock-3.18.0-py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from torch) (4.13.2)\n",
      "Collecting sympy>=1.13.3\n",
      "  Downloading sympy-1.14.0-py3-none-any.whl (6.3 MB)\n",
      "     ---------------------------------------- 6.3/6.3 MB 1.7 MB/s eta 0:00:00\n",
      "Requirement already satisfied: networkx in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from torchvision) (2.2.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from torchvision) (11.2.1)\n",
      "Collecting mpmath<1.4,>=1.1.0\n",
      "  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "     -------------------------------------- 536.2/536.2 kB 1.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Installing collected packages: mpmath, sympy, filelock, torch, torchvision, torchaudio\n",
      "Successfully installed filelock-3.18.0 mpmath-1.3.0 sympy-1.14.0 torch-2.7.0 torchaudio-2.7.0 torchvision-0.22.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script isympy.exe is installed in 'C:\\Users\\shril\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts torchfrtrace.exe and torchrun.exe are installed in 'C:\\Users\\shril\\AppData\\Roaming\\Python\\Python311\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting torch-geometric\n",
      "  Downloading torch_geometric-2.6.1-py3-none-any.whl (1.1 MB)\n",
      "     ---------------------------------------- 1.1/1.1 MB 1.6 MB/s eta 0:00:00\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.11.18-cp311-cp311-win_amd64.whl (443 kB)\n",
      "     -------------------------------------- 443.7/443.7 kB 1.5 MB/s eta 0:00:00\n",
      "Requirement already satisfied: fsspec in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from torch-geometric) (2025.3.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from torch-geometric) (3.1.6)\n",
      "Requirement already satisfied: numpy in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from torch-geometric) (2.2.5)\n",
      "Requirement already satisfied: psutil>=5.8.0 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from torch-geometric) (7.0.0)\n",
      "Requirement already satisfied: pyparsing in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from torch-geometric) (3.2.3)\n",
      "Requirement already satisfied: requests in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from torch-geometric) (2.32.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from torch-geometric) (4.67.1)\n",
      "Collecting aiohappyeyeballs>=2.3.0\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from aiohttp->torch-geometric) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.6.0-cp311-cp311-win_amd64.whl (120 kB)\n",
      "     -------------------------------------- 120.9/120.9 kB 1.4 MB/s eta 0:00:00\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.4.3-cp311-cp311-win_amd64.whl (38 kB)\n",
      "Collecting propcache>=0.2.0\n",
      "  Downloading propcache-0.3.1-cp311-cp311-win_amd64.whl (45 kB)\n",
      "     ---------------------------------------- 45.2/45.2 kB 1.1 MB/s eta 0:00:00\n",
      "Collecting yarl<2.0,>=1.17.0\n",
      "  Downloading yarl-1.20.0-cp311-cp311-win_amd64.whl (93 kB)\n",
      "     ---------------------------------------- 93.4/93.4 kB 2.6 MB/s eta 0:00:00\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from jinja2->torch-geometric) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from requests->torch-geometric) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from requests->torch-geometric) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from requests->torch-geometric) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from requests->torch-geometric) (2025.1.31)\n",
      "Requirement already satisfied: colorama in c:\\users\\shril\\appdata\\roaming\\python\\python311\\site-packages (from tqdm->torch-geometric) (0.4.6)\n",
      "Installing collected packages: propcache, multidict, frozenlist, aiohappyeyeballs, yarl, aiosignal, aiohttp, torch-geometric\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.11.18 aiosignal-1.3.2 frozenlist-1.6.0 multidict-6.4.3 propcache-0.3.1 torch-geometric-2.6.1 yarl-1.20.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 25.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install torch torchvision torchaudio\n",
    "!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a76b11e-51f0-499a-a4d7-9b8809f5f862",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Node features saved to features.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Convert email_data to DataFrame\n",
    "df = pd.DataFrame(email_data)\n",
    "\n",
    "# Group by sender and calculate features\n",
    "features = df.groupby(\"from_email\").agg({\n",
    "    \"num_links\": \"mean\",\n",
    "    \"num_attachments\": \"mean\",\n",
    "    \"is_html\": \"mean\",\n",
    "    \"subject\": \"count\"\n",
    "}).rename(columns={\"subject\": \"email_count\"})\n",
    "\n",
    "features.reset_index(inplace=True)\n",
    "features.rename(columns={\"from_email\": \"id\"}, inplace=True)\n",
    "features.to_csv(\"features.csv\", index=False)\n",
    "\n",
    "print(\"‚úÖ Node features saved to features.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e3b0db1-70b2-47f2-b1bb-f0074e60fcfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels saved to labels.csv\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "\n",
    "# Example list of emails and their labels (0 for legit, 1 for phishing)\n",
    "emails = [\n",
    "    {\"id\": \"iqac@cmrit.ac.in\", \"label\": 0},\n",
    "    {\"id\": \"viceprincipal@cmrit.ac.in\", \"label\": 0},\n",
    "    {\"id\": \"no-reply@mail.newsletter.instructables.com\", \"label\": 1},\n",
    "    {\"id\": \"randomphisher@badmail.com\", \"label\": 1}\n",
    "]\n",
    "\n",
    "# Define the output file name\n",
    "output_file = \"labels.csv\"\n",
    "\n",
    "# Write to CSV\n",
    "with open(output_file, mode=\"w\", newline=\"\") as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=[\"id\", \"label\"])\n",
    "    writer.writeheader()\n",
    "    writer.writerows(emails)\n",
    "\n",
    "print(f\"Labels saved to {output_file}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1087f108-0eae-422d-bb3e-b9666545353d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 4)) while a minimum of 1 is required by StandardScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m----------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     26\u001b[39m features_df = features_df.dropna(subset=[\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m])  \u001b[38;5;66;03m# Drop rows with NaN ID after mapping\u001b[39;00m\n\u001b[32m     27\u001b[39m features_df = features_df.sort_values(\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     28\u001b[39m x = torch.tensor(\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m     \u001b[43mStandardScaler\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mid\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m     30\u001b[39m     dtype=torch.float\n\u001b[32m     31\u001b[39m )\n\u001b[32m     33\u001b[39m \u001b[38;5;66;03m# 5. Prepare labels (ensure they align with features)\u001b[39;00m\n\u001b[32m     34\u001b[39m labels_df[\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m] = labels_df[\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m].map(id_map)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    321\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    322\u001b[39m         return_tuple = (\n\u001b[32m    323\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    324\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    325\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:918\u001b[39m, in \u001b[36mTransformerMixin.fit_transform\u001b[39m\u001b[34m(self, X, y, **fit_params)\u001b[39m\n\u001b[32m    903\u001b[39m         warnings.warn(\n\u001b[32m    904\u001b[39m             (\n\u001b[32m    905\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mThis object (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) has a `transform`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    913\u001b[39m             \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[32m    914\u001b[39m         )\n\u001b[32m    916\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    917\u001b[39m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m.transform(X)\n\u001b[32m    919\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    920\u001b[39m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fit(X, y, **fit_params).transform(X)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\preprocessing\\_data.py:894\u001b[39m, in \u001b[36mStandardScaler.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    892\u001b[39m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[32m    893\u001b[39m \u001b[38;5;28mself\u001b[39m._reset()\n\u001b[32m--> \u001b[39m\u001b[32m894\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\base.py:1389\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1382\u001b[39m     estimator._validate_params()\n\u001b[32m   1384\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1385\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1386\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1387\u001b[39m     )\n\u001b[32m   1388\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1389\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\preprocessing\\_data.py:930\u001b[39m, in \u001b[36mStandardScaler.partial_fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    898\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Online computation of mean and std on X for later scaling.\u001b[39;00m\n\u001b[32m    899\u001b[39m \n\u001b[32m    900\u001b[39m \u001b[33;03mAll of X is processed as a single batch. This is intended for cases\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    927\u001b[39m \u001b[33;03m    Fitted scaler.\u001b[39;00m\n\u001b[32m    928\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    929\u001b[39m first_call = \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mn_samples_seen_\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m930\u001b[39m X = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    932\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsc\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    934\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    935\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    936\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfirst_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    937\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    938\u001b[39m n_features = X.shape[\u001b[32m1\u001b[39m]\n\u001b[32m    940\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:2944\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2942\u001b[39m         out = X, y\n\u001b[32m   2943\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[32m-> \u001b[39m\u001b[32m2944\u001b[39m     out = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2945\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n\u001b[32m   2946\u001b[39m     out = _check_y(y, **check_params)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\validation.py:1130\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1128\u001b[39m     n_samples = _num_samples(array)\n\u001b[32m   1129\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_samples < ensure_min_samples:\n\u001b[32m-> \u001b[39m\u001b[32m1130\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1131\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mFound array with \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m sample(s) (shape=\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m) while a\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1132\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m minimum of \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m is required\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1133\u001b[39m             % (n_samples, array.shape, ensure_min_samples, context)\n\u001b[32m   1134\u001b[39m         )\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_min_features > \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m array.ndim == \u001b[32m2\u001b[39m:\n\u001b[32m   1137\u001b[39m     n_features = array.shape[\u001b[32m1\u001b[39m]\n",
      "\u001b[31mValueError\u001b[39m: Found array with 0 sample(s) (shape=(0, 4)) while a minimum of 1 is required by StandardScaler."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import GCNConv\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# 1. Load CSVs\n",
    "nodes_df = pd.read_csv('nodes.csv')\n",
    "edges_df = pd.read_csv('edges.csv')\n",
    "features_df = pd.read_csv('features.csv')\n",
    "labels_df = pd.read_csv('labels.csv')  # Optional\n",
    "\n",
    "# 2. Encode node IDs as integers\n",
    "le = LabelEncoder()\n",
    "nodes_df['node_idx'] = le.fit_transform(nodes_df['id'])\n",
    "id_map = dict(zip(nodes_df['id'], nodes_df['node_idx']))\n",
    "\n",
    "# 3. Create edge index (tensor)\n",
    "edges_df['source'] = edges_df['source'].map(id_map)\n",
    "edges_df['target'] = edges_df['target'].map(id_map)\n",
    "edges_df = edges_df.dropna()  # Remove unmapped edges\n",
    "edge_index = torch.tensor(edges_df[['source', 'target']].values.T, dtype=torch.long)\n",
    "\n",
    "# 4. Prepare node features\n",
    "features_df['id'] = features_df['id'].map(id_map)\n",
    "features_df = features_df.dropna(subset=['id'])  # Drop rows with NaN ID after mapping\n",
    "features_df = features_df.sort_values('id')\n",
    "x = torch.tensor(\n",
    "    StandardScaler().fit_transform(features_df.drop(columns='id').values),\n",
    "    dtype=torch.float\n",
    ")\n",
    "\n",
    "# 5. Prepare labels (ensure they align with features)\n",
    "labels_df['id'] = labels_df['id'].map(id_map)\n",
    "labels_df = labels_df.dropna(subset=['id'])  # Drop unmapped\n",
    "labels_df = labels_df.sort_values('id')\n",
    "\n",
    "# Align labels to feature nodes only\n",
    "merged_df = pd.merge(features_df, labels_df, on='id', how='inner')\n",
    "x = torch.tensor(\n",
    "    StandardScaler().fit_transform(merged_df.drop(columns=['id', 'label']).values),\n",
    "    dtype=torch.float\n",
    ")\n",
    "y = torch.tensor(merged_df['label'].values, dtype=torch.long)\n",
    "\n",
    "# 6. Build PyG Data object\n",
    "data = Data(x=x, edge_index=edge_index, y=y)\n",
    "\n",
    "# 7. Define a simple GNN\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(input_dim, hidden_dim)\n",
    "        self.conv2 = GCNConv(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index).relu()\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# 8. Train the GNN\n",
    "model = GCN(input_dim=x.shape[1], hidden_dim=16, output_dim=2)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "model.train()\n",
    "for epoch in range(100):\n",
    "    optimizer.zero_grad()\n",
    "    out = model(data)\n",
    "    loss = criterion(out, data.y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}: Loss = {loss.item():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf22240-522a-41e0-b46a-6a72638c8ee0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
